{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append( '..' )\n",
    "from VAE import *\n",
    "from VAE_smac import *\n",
    "from helpers.pc_stats import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup loaded (0.009823322296142578s)\n"
     ]
    }
   ],
   "source": [
    "data_dir  = os.path.normpath(os.path.join(os.getcwd(), \"../../runs/FIA/Com8_grown_together/oms\"))\n",
    "run_dir = os.path.normpath(os.path.join(os.getcwd(), \"../../runs/VAE/hyperparameter_optimization\"))\n",
    "results_dir = os.path.normpath(os.path.join(os.getcwd(), \"../../runs/VAE/results\"))\n",
    "test_configuration = False\n",
    "overwrite = False\n",
    "verbosity = 1\n",
    "framework = \"pytorch_jupyter\"\n",
    "outdir = Path(os.path.normpath(os.path.join(run_dir, f\"smac_vae_{framework}\")))\n",
    "\n",
    "# Logging (time and steps)\n",
    "last_timestamp = time.time()\n",
    "step = 0\n",
    "runtimes = {}\n",
    "\n",
    "\n",
    "time_step(message=\"Setup loaded\", verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded (2.3199915885925293s)\n",
      "Configuration space defined with estimated inf possible combinations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = read_data(data_dir, verbosity=verbosity)\n",
    "\n",
    "configuration_space = ConfigurationSpace(name=\"LD\", seed=42)\n",
    "hyperparameters = [\n",
    "    Constant(       \"original_dim\",             X.shape[1]),\n",
    "    Float(          \"input_dropout\",            (0.0, 0.5), default=0.25),\n",
    "    Integer(        \"intermediate_layers\",      (1, 5), default=2),\n",
    "    Integer(        \"intermediate_dimension\",   (10, 20), log=True, default=20),\n",
    "    Categorical(    \"intermediate_activation\",  [\"relu\", \"selu\", \"tanh\", \"leakyrelu\"], default=\"selu\"),\n",
    "    Integer(        \"latent_dimension\",         (10, 11), log=False, default=10),\n",
    "    Categorical(    \"solver\",                   [\"nadam\"], default=\"nadam\"),\n",
    "    Float(          \"learning_rate\",            (1e-4, 1e-2), log=True, default=1e-3)\n",
    "]\n",
    "configuration_space.add_hyperparameters(hyperparameters)\n",
    "forbidden_clauses = [\n",
    "    ForbiddenGreaterThanRelation(configuration_space[\"latent_dimension\"], configuration_space[\"intermediate_dimension\"])\n",
    "]\n",
    "configuration_space.add_forbidden_clauses(forbidden_clauses)\n",
    "if verbosity > 0: \n",
    "    print(f\"Configuration space defined with estimated {configuration_space.estimate_size()} possible combinations.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "        \"\"\"\n",
    "        Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\n",
    "        \"\"\"\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            z_mean_shape = backend.shape(z_mean)\n",
    "            batch   = z_mean_shape[0]\n",
    "            dim     = z_mean_shape[1]\n",
    "            epsilon = backend.random_normal(shape=(batch, dim))\n",
    "            return z_mean + backend.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class FIA_VAE():\n",
    "    def __init__(self, config:Configuration):\n",
    "        im_layers       = config[\"intermediate_layers\"]\n",
    "        im_dim          = config[\"intermediate_dimension\"]\n",
    "        activation_fun  = get_activation_function( config[\"intermediate_activation\"] )\n",
    "        \n",
    "        # Encoder\n",
    "        self.input      = Input(shape=(config[\"original_dim\"],), name='encoder_input')\n",
    "        self.im_enc     = Dropout( config[\"input_dropout\"] ) (self.input)\n",
    "        self.im_enc     = Dense( im_dim , activation=activation_fun ) (self.im_enc)\n",
    "        for i in range(1, im_layers):                                                              # Successive halfing of layers\n",
    "            if im_dim // 2**i <= config[\"latent_dimension\"]:\n",
    "                im_layers = i \n",
    "                break\n",
    "            self.im_enc = Dense( im_dim // 2**i, activation=activation_fun ) (self.im_enc)\n",
    "        self.mu         = Dense( config[\"latent_dimension\"], name='latent_mu' ) (self.im_enc)\n",
    "        self.sigma      = Dense( config[\"latent_dimension\"], name='latent_sigma' ) (self.im_enc)\n",
    "        self.z          = Sampling(name=\"Reparametrization\") ( [self.mu, self.sigma] )                                 \n",
    "\n",
    "        self.encoder = Model( self.input, [self.mu, self.sigma, self.z], name='encoder' )            # Instantiate encoder\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_input  = Input(shape=(config[\"latent_dimension\"], ), name='decoder_input')\n",
    "        prev_layer = self.decoder_input\n",
    "        for i in reversed(range(1, im_layers)):\n",
    "            self.im_dec =  Dense( im_dim // 2**i, activation=activation_fun) (prev_layer)\n",
    "            prev_layer = self.im_dec\n",
    "        self.im_dec = Dense(im_dim, activation=activation_fun) (prev_layer)\n",
    "        self.output  = Dense(config[\"original_dim\"]) (self.im_dec)\n",
    "\n",
    "        self.decoder = Model(self.decoder_input, self.output, name='decoder')                        # Instantiate decoder\n",
    "\n",
    "        # VAE\n",
    "        self.vae_outputs = self.decoder(self.encoder(self.input)[2])\n",
    "        self.vae         = Model(self.input, self.vae_outputs, name='vae')\n",
    "\n",
    "        # Loss trackers\n",
    "        self.reconstruction_loss = keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss = keras.metrics.Mean(name=\"kl_loss\")\n",
    "        self.loss = keras.metrics.Mean(name=\"total_loss\")\n",
    "\n",
    "        # Define optimizer\n",
    "        self.optimizer = get_solver( config[\"solver\"] )( config[\"learning_rate\"] )\n",
    "\n",
    "        # Compile VAE\n",
    "        self.vae.compile(optimizer=self.optimizer, loss=self.kl_reconstruction_loss, metrics = [ \"mse\" ])\n",
    "\n",
    "    def encode(self, data):\n",
    "        return self.encoder.predict(data)[2]\n",
    "    \n",
    "    def encode_mu(self, data):\n",
    "        return self.encoder.predict(data)[0]\n",
    "    \n",
    "    def decode(self, data):\n",
    "        return self.decoder.predict(data)\n",
    "    \n",
    "    def reconstruct(self, data):\n",
    "        return self.decode(self.encode(data))\n",
    "    \n",
    "    def save_model(self, save_folder, suffix:str=\"\"):\n",
    "        self.vae.save(os.path.join(save_folder, f'VAE{suffix}.h5'))\n",
    "        self.encoder.save(os.path.join(save_folder, f'VAE_encoder{suffix}.h5'))\n",
    "        self.decoder.save(os.path.join(save_folder, f'VAE_decoder{suffix}.h5'))\n",
    "        \n",
    "    def load_vae(self, save_path):                       \n",
    "        self.vae = keras.models.load_model(save_path)\n",
    "        self.vae.compile(optimizer=self.optimizer, \n",
    "                         loss=self.kl_reconstruction_loss, \n",
    "                         metrics = ['mse'])\n",
    "        \n",
    "    def load_encoder(self, save_path):\n",
    "        self.encoder = keras.models.load_model(save_path)\n",
    "        \n",
    "    def load_decoder(self, save_path):\n",
    "        self.decoder = keras.models.load_model(save_path)\n",
    "    \n",
    "    def kl_reconstruction_loss(self, true, pred):\n",
    "        \"\"\"\n",
    "        Loss function for Kullback-Leibler + Reconstruction loss\n",
    "\n",
    "        Args:\n",
    "            true: True values\n",
    "            pred: Predicted values\n",
    "        Returns:\n",
    "            Loss = Kullback-Leibler + Reconstruction loss\n",
    "        \"\"\"\n",
    "        mse = MeanSquaredError()\n",
    "        self.reconstruction_loss = mse(true, pred)\n",
    "        self.kl_loss = backend.mean(-0.5 * backend.sum( 1.0 + self.sigma - backend.square(self.mu) - backend.exp(self.sigma), axis=-1))\n",
    "        self.loss = self.reconstruction_loss + self.kl_loss\n",
    "\n",
    "        return self.loss\n",
    "    \n",
    "    def train(self, training_data_in, training_data_out, validation_data_in, validation_data_out,\n",
    "              epochs:int, batch_size:int, callbacks:list, verbosity:int=0):\n",
    "        self.vae.fit(training_data_in, training_data_out,\n",
    "                     validation_data = (validation_data_in, validation_data_out),\n",
    "                     epochs = epochs, batch_size = batch_size, \n",
    "                     callbacks = callbacks, verbose = verbosity)\n",
    "    \n",
    "    def evaluate(self, test_data_in, test_data_out, verbosity:int=0):\n",
    "        loss, mse = self.vae.evaluate(test_data_in, test_data_out, verbose=verbosity)\n",
    "        return (loss, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIA_VAE_tune:\n",
    "    def __init__(self, X, test_size:float, configuration_space:ConfigurationSpace, model_builder,\n",
    "                 log_dir:str, batch_size:int=16, verbosity:int=0, gpu:bool=False):\n",
    "        self.configuration_space = configuration_space\n",
    "        self.model_builder = model_builder\n",
    "        self.training_data, self.test_data = train_test_split(X, test_size=test_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.log_dir = log_dir\n",
    "        self.verbosity = verbosity\n",
    "\n",
    "    def train(self, config: Configuration, seed: int = 0, budget:int=25) -> float:\n",
    "        \"\"\"\n",
    "        Method to train the model\n",
    "\n",
    "        Args:\n",
    "            config: Configuration to be trained upon\n",
    "            seed: initializing seed\n",
    "            budget: number of epochs to be used in training\n",
    "        \n",
    "        Returns:\n",
    "            Average loss of the model\n",
    "        \"\"\"\n",
    "        keras.utils.set_random_seed(seed)\n",
    "\n",
    "        # Definition\n",
    "        model = self.model_builder(config)\n",
    "\n",
    "        # Fitting\n",
    "        callbacks = []\n",
    "        if self.verbosity >= 1:\n",
    "            log_dir = os.path.join(self.log_dir,  datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "            callbacks.append( TensorBoard(log_dir=log_dir, write_graph=True, write_images=True,\n",
    "                                          update_freq='epoch') )\n",
    "\n",
    "        model.train(training_data_in=self.training_data, training_data_out=self.training_data,\n",
    "                    validation_data_in=self.training_data, validation_data_out=self.training_data,\n",
    "                    epochs=int(budget), batch_size=self.batch_size,\n",
    "                    callbacks=callbacks, verbosity=self.verbosity)\n",
    "\n",
    "\n",
    "        # Evaluation\n",
    "        loss, mse = model.evaluate(self.test_data, self.test_data, verbosity=self.verbosity)\n",
    "        \n",
    "        # Clearing model parameters\n",
    "        keras.backend.clear_session()\n",
    "                \n",
    "        return loss\n",
    "    \n",
    "fia_vae_tune = FIA_VAE_tune( X, test_size=0.2, configuration_space=configuration_space, model_builder=FIA_VAE,\n",
    "                                batch_size=64, log_dir=os.path.join(outdir, \"log\"), verbosity=verbosity, gpu=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:95] Reducing the number of initial configurations from 10 to 5 (max_ratio == 0.25).\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "SMAC defined. Overwriting: False (33.57362484931946s)\n"
     ]
    }
   ],
   "source": [
    "scenario = Scenario( fia_vae_tune.configuration_space, deterministic=True,\n",
    "                     n_trials=20, min_budget=2, max_budget=100,\n",
    "                     n_workers=1, output_directory=outdir,\n",
    "                     walltime_limit=np.inf, cputime_limit=np.inf, trial_memory_limit=None )   # Max RAM in Bytes (not MB)\n",
    "                    \n",
    "initial_design = MultiFidelityFacade.get_initial_design(scenario, n_configs=10)\n",
    "intensifier = Hyperband(scenario, incumbent_selection=\"highest_budget\")\n",
    "facade = MultiFidelityFacade( scenario, fia_vae_tune.train, \n",
    "                              initial_design=initial_design, intensifier=intensifier,\n",
    "                              overwrite=overwrite, logging_level=30-verbosity*10 )\n",
    "time_step(message=f\"SMAC defined. Overwriting: {overwrite}\", verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 2, and max budget 100.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [27, 9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [12, 4, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [6, 2]\n",
      "[INFO][successive_halving.py:325] --- Bracket 3: [4]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [3.7037037037037033, 11.11111111111111, 33.33333333333333, 100.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [11.11111111111111, 33.33333333333333, 100.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [33.33333333333333, 100.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 3: [100.0]\n",
      "Train on 54 samples, validate on 54 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:18:58.506335: W tensorflow/c/c_api.cc:305] Operation '{name:'training_6/Nadam/latent_mu_4/bias/m/Assign' id:3944 op device:{requested: '', assigned: ''} def:{{{node training_6/Nadam/latent_mu_4/bias/m/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training_6/Nadam/latent_mu_4/bias/m, training_6/Nadam/latent_mu_4/bias/m/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.3775e-05 - mse: 1.3773e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/keras/src/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2024-04-10 20:18:59.903229: W tensorflow/c/c_api.cc:305] Operation '{name:'loss_3/mul' id:3686 op device:{requested: '', assigned: ''} def:{{{node loss_3/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss_3/mul/x, loss_3/decoder_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 29ms/sample - loss: 1.3775e-05 - mse: 1.3773e-05 - val_loss: 1.5851e-04 - val_mse: 1.2826e-05\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:00.407246: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-10 20:19:00.407296: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - ETA: 0s - loss: 1.5858e-04 - mse: 1.2971e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:01.334881: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-10 20:19:01.344229: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 26ms/sample - loss: 1.5858e-04 - mse: 1.2971e-05 - val_loss: 3.6788e-05 - val_mse: 1.2444e-05\n",
      "Epoch 3/3\n",
      "54/54 [==============================] - 1s 26ms/sample - loss: 3.6857e-05 - mse: 1.2473e-05 - val_loss: 3.3574e-05 - val_mse: 1.2106e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:05<00:49,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 54 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:03.819585: W tensorflow/c/c_api.cc:305] Operation '{name:'training/Nadam/dense_1/kernel/v/Assign' id:628 op device:{requested: '', assigned: ''} def:{{{node training/Nadam/dense_1/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Nadam/dense_1/kernel/v, training/Nadam/dense_1/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 2.8531e-05 - mse: 2.8515e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:05.099751: W tensorflow/c/c_api.cc:305] Operation '{name:'loss/mul' id:299 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/decoder_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 29ms/sample - loss: 2.8531e-05 - mse: 2.8515e-05 - val_loss: 3.1457e-05 - val_mse: 2.9103e-05\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:05.602661: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-10 20:19:05.602718: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - ETA: 0s - loss: 2.8906e-05 - mse: 2.6508e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:06.505184: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-10 20:19:06.506565: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 26ms/sample - loss: 2.8906e-05 - mse: 2.6508e-05 - val_loss: 2.9356e-05 - val_mse: 2.9104e-05\n",
      "Epoch 3/3\n",
      "54/54 [==============================] - 1s 25ms/sample - loss: 2.9529e-05 - mse: 2.9276e-05 - val_loss: 2.7958e-05 - val_mse: 2.7704e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:10<00:42,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54 samples, validate on 54 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:08.920251: W tensorflow/c/c_api.cc:305] Operation '{name:'training/Nadam/latent_sigma/bias/v/Assign' id:623 op device:{requested: '', assigned: ''} def:{{{node training/Nadam/latent_sigma/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Nadam/latent_sigma/bias/v, training/Nadam/latent_sigma/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 1.3197e-05 - mse: 1.3197e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:10.203465: W tensorflow/c/c_api.cc:305] Operation '{name:'loss/mul' id:299 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/decoder_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 2s 28ms/sample - loss: 1.3197e-05 - mse: 1.3197e-05 - val_loss: 0.0013 - val_mse: 9.2401e-06\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:10.703433: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-04-10 20:19:10.703483: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - ETA: 0s - loss: 0.0013 - mse: 9.6538e-06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 20:19:11.715709: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-04-10 20:19:11.717029: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 1s 28ms/sample - loss: 0.0013 - mse: 9.6538e-06 - val_loss: 5.6824e-05 - val_mse: 7.4119e-06\n",
      "Epoch 3/3\n",
      "54/54 [==============================] - ETA: 0s - loss: 5.7198e-05 - mse: 7.5541e-06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:15<01:03,  7.88s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m incumbent \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfacade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmac_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfia_vae_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/MStoML/skripts/VAE/VAE_smac.py:164\u001b[0m, in \u001b[0;36mrun_optimization\u001b[0;34m(facade, smac_model, verbose_steps, verbosity)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbosity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting search:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 164\u001b[0m     \u001b[43mask_tell_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfacade\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacade\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmac_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msmac_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m incumbent \u001b[38;5;241m=\u001b[39m facade\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[1;32m    166\u001b[0m time_step(message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch completed\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbosity\u001b[38;5;241m=\u001b[39mverbosity)\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/MStoML/skripts/VAE/VAE_smac.py:144\u001b[0m, in \u001b[0;36mask_tell_optimization\u001b[0;34m(facade, smac_model, n, verbosity)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbosity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mdict\u001b[39m(info\u001b[38;5;241m.\u001b[39mconfig)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 144\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43msmac_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m value \u001b[38;5;241m=\u001b[39m TrialValue(cost\u001b[38;5;241m=\u001b[39mloss, time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39macc_time, starttime\u001b[38;5;241m=\u001b[39macc_time, endtime\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m    147\u001b[0m facade\u001b[38;5;241m.\u001b[39mtell(info, value)\n",
      "Cell \u001b[0;32mIn[22], line 35\u001b[0m, in \u001b[0;36mFIA_VAE_tune.train\u001b[0;34m(self, config, seed, budget)\u001b[0m\n\u001b[1;32m     31\u001b[0m     log_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_dir,  datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     32\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend( TensorBoard(log_dir\u001b[38;5;241m=\u001b[39mlog_dir, write_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, write_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m                                   update_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m, profile_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) )\n\u001b[0;32m---> 35\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Evaluation\u001b[39;00m\n\u001b[1;32m     42\u001b[0m loss, mse \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity)\n",
      "Cell \u001b[0;32mIn[12], line 117\u001b[0m, in \u001b[0;36mFIA_VAE.train\u001b[0;34m(self, training_data_in, training_data_out, validation_data_in, validation_data_out, epochs, batch_size, callbacks, verbosity)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, training_data_in, training_data_out, validation_data_in, validation_data_out,\n\u001b[1;32m    116\u001b[0m           epochs:\u001b[38;5;28mint\u001b[39m, batch_size:\u001b[38;5;28mint\u001b[39m, callbacks:\u001b[38;5;28mlist\u001b[39m, verbosity:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_data_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/keras/src/engine/training_v1.py:856\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    855\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 856\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/keras/src/engine/training_arrays_v1.py:734\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_steps` should not be specified if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_data` is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m         )\n\u001b[1;32m    732\u001b[0m     val_x, val_y, val_sample_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_sample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps_per_epoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/keras/src/engine/training_arrays_v1.py:460\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m_compile_distribution:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# Since we create a new clone from the original model we need to\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# copy the weights back to the original model before we can run\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# validation.\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     distributed_training_utils_v1\u001b[38;5;241m.\u001b[39m_copy_weights_to_original_model(\n\u001b[1;32m    457\u001b[0m         model, ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN\n\u001b[1;32m    458\u001b[0m     )\n\u001b[0;32m--> 460\u001b[0m val_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_iteration\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_in_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepared_feed_values_from_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_iterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val_results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    475\u001b[0m     val_results \u001b[38;5;241m=\u001b[39m [val_results]\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/keras/src/engine/training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[1;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[1;32m    418\u001b[0m )\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/keras/src/backend.py:4607\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   4599\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4603\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[1;32m   4604\u001b[0m ):\n\u001b[1;32m   4605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4607\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n\u001b[1;32m   4609\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4610\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4611\u001b[0m     fetched[: \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   4612\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4613\u001b[0m )\n",
      "File \u001b[0;32m/mnt/lustre/groups/link/linca945/.conda/envs/MStoML/lib/python3.11/site-packages/tensorflow/python/client/session.py:1505\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1504\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1505\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1508\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1509\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "incumbent = run_optimization(facade=facade, smac_model=fia_vae_tune, verbose_steps=10, verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
