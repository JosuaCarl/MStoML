{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append( '..' )\n",
    "from VAE.vae import *\n",
    "from VAE.VAE_smac import *\n",
    "from helpers.pc_stats import *\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup loaded (0.6456279754638672s)\n"
     ]
    }
   ],
   "source": [
    "data_dir  = os.path.normpath(os.path.join(os.getcwd(), \"../../runs/FIA/Com8_grown_together/oms\"))\n",
    "run_dir = os.path.normpath(os.path.join(os.getcwd(), \"../../runs/VAE/hyperparameter_optimization\"))\n",
    "results_dir = os.path.normpath(os.path.join(os.getcwd(), \"../../runs/VAE/results\"))\n",
    "test_configuration = False\n",
    "overwrite = False\n",
    "verbosity = 1\n",
    "framework = \"pytorch_jupyter\"\n",
    "outdir = Path(os.path.normpath(os.path.join(run_dir, f\"smac_vae_{framework}\")))\n",
    "\n",
    "# Logging (time and steps)\n",
    "last_timestamp = time.time()\n",
    "step = 0\n",
    "runtimes = {}\n",
    "\n",
    "\n",
    "time_step(message=\"Setup loaded\", verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded (5.064542531967163s)\n",
      "Configuration space defined with estimated inf possible combinations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = read_data(data_dir, verbosity=verbosity)\n",
    "\n",
    "configuration_space = ConfigurationSpace(name=\"LD\", seed=42)\n",
    "hyperparameters = [\n",
    "    Constant(       \"original_dim\",             X.shape[1]),\n",
    "    Float(          \"input_dropout\",            (0.0, 0.5), default=0.25),\n",
    "    Integer(        \"intermediate_layers\",      (1, 5), default=2),\n",
    "    Integer(        \"intermediate_dimension\",   (1, 20), log=True, default=4),\n",
    "    Categorical(    \"intermediate_activation\",  [\"relu\", \"selu\", \"tanh\", \"leakyrelu\"], default=\"leakyrelu\"),\n",
    "    Integer(        \"latent_dimension\",         (1, 10), log=False, default=2),\n",
    "    Categorical(    \"solver\",                   [\"nadam\"], default=\"nadam\"),\n",
    "    Float(          \"learning_rate\",            (1e-4, 1e-2), log=True, default=1e-3)\n",
    "]\n",
    "configuration_space.add_hyperparameters(hyperparameters)\n",
    "forbidden_clauses = [\n",
    "    ForbiddenGreaterThanRelation(configuration_space[\"latent_dimension\"], configuration_space[\"intermediate_dimension\"])\n",
    "]\n",
    "configuration_space.add_forbidden_clauses(forbidden_clauses)\n",
    "if verbosity > 0: \n",
    "    print(f\"Configuration space defined with estimated {configuration_space.estimate_size()} possible combinations.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIA_VAE_tune:\n",
    "    \"\"\"\n",
    "    Class for running the SMAC3 tuning\n",
    "    \"\"\"\n",
    "    def __init__(self, X, test_size:float, configuration_space:ConfigurationSpace, model_builder,\n",
    "                 log_dir:str, batch_size:int=16, verbosity:int=0, gpu:bool=False, name:str=\"smac_vae\"):\n",
    "        self.configuration_space = configuration_space\n",
    "        self.model_builder = model_builder\n",
    "        self.training_data, self.test_data = train_test_split(X, test_size=test_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.log_dir = log_dir\n",
    "        self.verbosity = verbosity\n",
    "        self.gpu = gpu\n",
    "        self.name = name\n",
    "        self.count = 0\n",
    "\n",
    "    def train(self, config:Configuration, seed:int=0, budget:int=25) -> float:\n",
    "        \"\"\"\n",
    "        Method to train the model\n",
    "\n",
    "        Args:\n",
    "            config: Configuration to be trained upon\n",
    "            seed: initializing seed\n",
    "            budget: number of epochs to be used in training\n",
    "        \n",
    "        Returns:\n",
    "            Average loss of the model\n",
    "        \"\"\"\n",
    "        time_step(\"Start\", verbosity=self.verbosity, min_verbosity=2)\n",
    "        keras.utils.set_random_seed(seed)\n",
    "\n",
    "        # Definition\n",
    "        model = self.model_builder(config)\n",
    "        if self.verbosity >= 3:\n",
    "            model.summary()\n",
    "            print_utilization(gpu=self.gpu)\n",
    "        time_step(\"Model built\", verbosity=self.verbosity, min_verbosity=2)\n",
    "\n",
    "        # Fitting\n",
    "        callbacks = []\n",
    "        run =  mlflow.start_run(run_name=f\"fia_vae_hptune_{self.count}\", nested=True)\n",
    "        callbacks.append( mlflow.keras.MlflowCallback(run) )\n",
    "        model.fit(x=self.training_data, y=self.training_data, validation_split=0.2,\n",
    "                  batch_size=self.batch_size, epochs=int(budget),\n",
    "                  callbacks=callbacks, verbose=self.verbosity)\n",
    "\n",
    "        if self.verbosity >= 3:\n",
    "            print(\"After training utilization:\")\n",
    "            print_utilization(gpu=self.gpu)\n",
    "        time_step(\"Model trained\", verbosity=self.verbosity, min_verbosity=2)\n",
    "\n",
    "        # Evaluation\n",
    "        loss, recon_loss, kl_loss = model.evaluate(self.test_data, self.test_data,\n",
    "                                                   batch_size=self.batch_size, verbose=self.verbosity)\n",
    "        \n",
    "        mlflow.log_params(config)\n",
    "        mlflow.log_metrics({\"eval-loss\": loss, \"eval-reconstruction_loss\": recon_loss, \"eval-kl_loss\": kl_loss},\n",
    "                           step=int(budget) + 1)\n",
    "        time_step(\"Model evaluated\", verbosity=self.verbosity, min_verbosity=2)        \n",
    "        \n",
    "        # Clearing model parameters\n",
    "        keras.backend.clear_session()\n",
    "        self.count += 1\n",
    "        time_step(\"Session cleared\", verbosity=self.verbosity, min_verbosity=2)\n",
    "                \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fia_vae_tune = FIA_VAE_tune( X, test_size=0.2, configuration_space=configuration_space, model_builder=FIA_VAE,\n",
    "                                batch_size=64, log_dir=os.path.join(outdir, \"log\"), verbosity=verbosity, gpu=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_initial_design.py:82] Using `n_configs` and ignoring `n_configs_per_hyperparameter`.\n",
      "[INFO][abstract_initial_design.py:95] Reducing the number of initial configurations from 10 to 5 (max_ratio == 0.25).\n",
      "[INFO][abstract_initial_design.py:147] Using 5 initial design configurations and 0 additional configurations.\n",
      "SMAC defined. Overwriting: False (601.848438501358s)\n"
     ]
    }
   ],
   "source": [
    "scenario = Scenario( fia_vae_tune.configuration_space, deterministic=True,\n",
    "                     n_trials=20, min_budget=2, max_budget=100,\n",
    "                     n_workers=1, output_directory=outdir,\n",
    "                     walltime_limit=np.inf, cputime_limit=np.inf, trial_memory_limit=None )   # Max RAM in Bytes (not MB)\n",
    "                    \n",
    "initial_design = MultiFidelityFacade.get_initial_design(scenario, n_configs=10)\n",
    "intensifier = Hyperband(scenario, incumbent_selection=\"highest_budget\")\n",
    "facade = MultiFidelityFacade( scenario, fia_vae_tune.train, \n",
    "                              initial_design=initial_design, intensifier=intensifier,\n",
    "                              overwrite=overwrite, logging_level=30-verbosity*10 )\n",
    "time_step(message=f\"SMAC defined. Overwriting: {overwrite}\", verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting search:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO][abstract_intensifier.py:305] Using only one seed for deterministic scenario.\n",
      "[INFO][successive_halving.py:164] Successive Halving uses budget type BUDGETS with eta 3, min budget 2, and max budget 100.\n",
      "[INFO][successive_halving.py:323] Number of configs in stage:\n",
      "[INFO][successive_halving.py:325] --- Bracket 0: [27, 9, 3, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 1: [12, 4, 1]\n",
      "[INFO][successive_halving.py:325] --- Bracket 2: [6, 2]\n",
      "[INFO][successive_halving.py:325] --- Bracket 3: [4]\n",
      "[INFO][successive_halving.py:327] Budgets in stage:\n",
      "[INFO][successive_halving.py:329] --- Bracket 0: [3.7037037037037033, 11.11111111111111, 33.33333333333333, 100.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 1: [11.11111111111111, 33.33333333333333, 100.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 2: [33.33333333333333, 100.0]\n",
      "[INFO][successive_halving.py:329] --- Bracket 3: [100.0]\n",
      "Configuration: {'input_dropout': 0.27244159149844843, 'intermediate_activation': 'leakyrelu', 'intermediate_dimension': 16, 'intermediate_layers': 4, 'latent_dimension': 8, 'learning_rate': 0.001105851072569646, 'original_dim': 825000, 'solver': 'nadam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - kl_loss: -0.0000e+00 - loss: 0.0014 - reconstruction_loss: 0.0014 - val_kl_loss: 0.0013 - val_loss: 0.0016 - val_reconstruction_loss: 2.1853e-04\n",
      "Epoch 2/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - kl_loss: 0.0053 - loss: 0.0055 - reconstruction_loss: 1.7508e-04 - val_kl_loss: 1.9976e-04 - val_loss: 2.3407e-04 - val_reconstruction_loss: 3.4304e-05\n",
      "Epoch 3/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - kl_loss: 7.7525e-04 - loss: 8.1374e-04 - reconstruction_loss: 3.8495e-05 - val_kl_loss: 1.2806e-04 - val_loss: 1.3254e-04 - val_reconstruction_loss: 4.4745e-06\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - kl_loss: 1.6230e-04 - loss: 1.7224e-04 - reconstruction_loss: 9.9341e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:27<04:10, 27.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'input_dropout': 0.30846699843737846, 'intermediate_activation': 'selu', 'intermediate_dimension': 6, 'intermediate_layers': 2, 'latent_dimension': 2, 'learning_rate': 0.00032105778495503974, 'original_dim': 825000, 'solver': 'nadam'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step - kl_loss: 4.7684e-07 - loss: 0.0010 - reconstruction_loss: 0.0010 - val_kl_loss: 1.5759e-04 - val_loss: 7.4161e-04 - val_reconstruction_loss: 5.8402e-04\n",
      "Epoch 2/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - kl_loss: 6.1980e-04 - loss: 0.0012 - reconstruction_loss: 6.0224e-04 - val_kl_loss: -0.0000e+00 - val_loss: 3.8837e-04 - val_reconstruction_loss: 3.8837e-04\n",
      "Epoch 3/3\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - kl_loss: -0.0000e+00 - loss: 3.1588e-04 - reconstruction_loss: 3.1588e-04 - val_kl_loss: 3.1888e-06 - val_loss: 1.9292e-04 - val_reconstruction_loss: 1.8973e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - kl_loss: 4.2021e-06 - loss: 9.2426e-05 - reconstruction_loss: 8.8224e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:55<03:41, 27.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'input_dropout': 0.0690914756743069, 'intermediate_activation': 'leakyrelu', 'intermediate_dimension': 1, 'intermediate_layers': 5, 'latent_dimension': 1, 'learning_rate': 0.0003910933172251061, 'original_dim': 825000, 'solver': 'nadam'}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=f\"fia_vae_hptune_test\"):\n",
    "    incumbent = run_optimization(facade=facade, smac_model=fia_vae_tune, verbose_steps=10, verbosity=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch\n"
     ]
    }
   ],
   "source": [
    "from keras import backend\n",
    "\n",
    "print(backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
