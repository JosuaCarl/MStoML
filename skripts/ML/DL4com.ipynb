{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: OPENMS_DATA_PATH environment variable already exists. pyOpenMS will use it (C:\\Program Files\\OpenMS-3.1.0\\share\\OpenMS) to locate data in the OpenMS share folder (e.g., the unimod database), instead of the default (c:\\Users\\JosuaCarl\\miniconda3\\envs\\gemml\\Lib\\site-packages\\pyopenms\\share/OpenMS).\n",
      "WARNING:tensorflow:From c:\\Users\\JosuaCarl\\miniconda3\\envs\\gemml\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append( '../FIA' )\n",
    "sys.path.append( '../ML' )\n",
    "\n",
    "from FIA import *\n",
    "from ML4com import *\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experiments:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:04<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading names:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "info_dir = \"../../data/comm8_self\"\n",
    "data_dir = \"../../runs/FIA/comm8/oms\"\n",
    "run_dir = \"../../runs/ML/try\"\n",
    "\n",
    "info_dir = os.path.normpath(os.path.join(os.getcwd(), info_dir))\n",
    "data_dir = os.path.normpath(os.path.join(os.getcwd(), data_dir))\n",
    "run_dir = os.path.normpath(os.path.join(os.getcwd(), run_dir))\n",
    "\n",
    "strains = pd.read_csv(os.path.join(info_dir, \"strains.tsv\"), sep=\"\\t\")\n",
    "comm8 = pd.read_csv(os.path.join(info_dir, \"comm8.tsv\"), sep=\"\\t\")\n",
    "\n",
    "fia_df = load_fia_df(data_dir, file_ending=\".mzML\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned_dfs = bin_df_stepwise_batch(fia_df, binning_var=\"mz\", binned_var=\"inty\", statistic=\"sum\", start=50.0, stop=1700.0, step=0.002)\n",
    "# binned_dfs.to_csv(os.path.join(run_dir, \"data_matrix.tsv\"), sep=\"\\t\")\n",
    "binned_dfs = pd.read_csv(os.path.join(run_dir, \"data_matrix.tsv\"), sep=\"\\t\", index_col=\"mz\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "binned_dfs[:] =  scaler.fit_transform(binned_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825000, 68)\n",
      "(68, 8)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(binned_dfs.shape)\n",
    "print(comm8.shape)\n",
    "print(strains.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Feature_combination_1 (Den  (None, 1000)              825001000 \n",
      " se)                                                             \n",
      "                                                                 \n",
      " Feature_combination_2 (Den  (None, 1000)              1001000   \n",
      " se)                                                             \n",
      "                                                                 \n",
      " Feature_interpretation_1 (  (None, 100)               100100    \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " Feature_interpretation_2 (  (None, 10)                1010      \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 826103110 (-990554856.00 Byte)\n",
      "Trainable params: 826103110 (-990554856.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JosuaCarl\\miniconda3\\envs\\gemml\\Lib\\site-packages\\keras\\src\\utils\\layer_utils.py:146: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  total_memory_size += weight_shape * per_param_size\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_sequential\")\n",
    "model.add(keras.Input(shape=(825000,)))\n",
    "model.add(layers.Dense(1000, activation=\"relu\", name=\"Feature_combination_1\"))\n",
    "model.add(layers.Dense(1000, activation=\"relu\", name=\"Feature_combination_2\"))\n",
    "model.add(layers.Dense(100, name=\"Feature_interpretation_1\"))\n",
    "model.add(layers.Dense(10, name=\"Feature_interpretation_2\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
