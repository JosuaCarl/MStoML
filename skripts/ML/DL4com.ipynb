{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: OPENMS_DATA_PATH environment variable already exists. pyOpenMS will use it (C:\\Program Files\\OpenMS-3.1.0\\share\\OpenMS) to locate data in the OpenMS share folder (e.g., the unimod database), instead of the default (c:\\Users\\JosuaCarl\\miniconda3\\envs\\gemml\\Lib\\site-packages\\pyopenms\\share/OpenMS).\n",
      "WARNING:tensorflow:From c:\\Users\\JosuaCarl\\miniconda3\\envs\\gemml\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append( '../FIA' )\n",
    "sys.path.append( '../ML' )\n",
    "\n",
    "from FIA import *\n",
    "from ML4com import *\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, activations\n",
    "\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experiments:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:01<00:00, 64.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading names:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 71988.05it/s]\n"
     ]
    }
   ],
   "source": [
    "info_dir = \"../../data/comm8_self\"\n",
    "data_dir = \"../../runs/FIA/comm8/oms\"\n",
    "run_dir = \"../../runs/ML/try\"\n",
    "\n",
    "info_dir = os.path.normpath(os.path.join(os.getcwd(), info_dir))\n",
    "data_dir = os.path.normpath(os.path.join(os.getcwd(), data_dir))\n",
    "run_dir = os.path.normpath(os.path.join(os.getcwd(), run_dir))\n",
    "\n",
    "strains = pd.read_csv(os.path.join(info_dir, \"strains.tsv\"), sep=\"\\t\")\n",
    "comm8 = pd.read_csv(os.path.join(info_dir, \"comm8.tsv\"), sep=\"\\t\")\n",
    "\n",
    "fia_df = load_fia_df(data_dir, file_ending=\".mzML\", separator=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binned_dfs = bin_df_stepwise_batch(fia_df, binning_var=\"mz\", binned_var=\"inty\", statistic=\"sum\", start=50.0, stop=1700.0, step=0.002)\n",
    "# binned_dfs.to_csv(os.path.join(run_dir, \"data_matrix.tsv\"), sep=\"\\t\")\n",
    "binned_dfs = pd.read_csv(os.path.join(run_dir, \"data_matrix.tsv\"), sep=\"\\t\", index_col=\"mz\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "binned_dfs[:] =  scaler.fit_transform(binned_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825000, 68)\n",
      "(68, 8)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    "print(binned_dfs.shape)\n",
    "print(comm8.shape)\n",
    "print(strains.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MS_community_prediction\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Feature_combination_1 (Den  (None, 8, 68, 1000)       825001000 \n",
      " se)                                                             \n",
      "                                                                 \n",
      " Feature_combination_2 (Den  (None, 8, 68, 100)        100100    \n",
      " se)                                                             \n",
      "                                                                 \n",
      " Feature_interpretation_1 (  (None, 8, 68, 100)        10100     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " Feature_interpretation_2 (  (None, 8, 68, 100)        10100     \n",
      " Dense)                                                          \n",
      "                                                                 \n",
      " Feature_separation_1 (Dens  (None, 8, 68, 100)        10100     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " Decision (Dense)            (None, 8, 68, 8)          808       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 825132208 (-994438464.00 Byte)\n",
      "Trainable params: 825132208 (-994438464.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"MS_community_prediction\")\n",
    "model.add(keras.Input(shape=(8,68,825000)))\n",
    "model.add(layers.Dense(512, activation=activations.tanh, name=\"Feature_combination_1\"))\n",
    "model.add(layers.Dense(128, activation=activations.relu, name=\"Feature_combination_2\"))\n",
    "model.add(layers.Dense(128,  activation=activations.relu, name=\"Feature_interpretation_1\"))\n",
    "model.add(layers.Dense(128,  activation=activations.relu, name=\"Feature_interpretation_2\"))\n",
    "model.add(layers.Dense(100,  activation=activations.sigmoid, name=\"Feature_separation_1\"))\n",
    "model.add(layers.Dense(8,  activation=activations.softmax, name=\"Decision\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binned_dfs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = binned_dfs\n",
    "y = comm8\n",
    "\n",
    "test_index = sample_without_replacement(68, math.ceil(68/5))\n",
    "test_data  = X.iloc[test_index]\n",
    "test_labels = y.iloc[test_index]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)        # non stratified: kf = KFold(n_splits = 5)\n",
    "for train_index, val_index in skf.split(X, y):\n",
    "\ttraining_data = X.iloc[train_index]\n",
    "\ttraining_labels = y.iloc[train_index]\n",
    "\tvalidation_data = X.iloc[val_index]\n",
    "\tvalidation_labels = y.iloc[val_index]\n",
    "\n",
    "\tmodel.fit(training_data, training_labels, epochs=10)\n",
    "\ttest_loss, test_acc = model.evaluate(validation_data,  validation_labels, verbose=\"auto\")\n",
    "\t\n",
    "\tprobability_model = keras.Sequential([model, keras.layers.Softmax()])\n",
    "\tpredictions = probability_model.predict(test_data)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61, 55, 67, 62, 66, 27, 51, 21,  0, 50, 17, 36, 12, 59])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MStoML.skripts.FIA.FIA import quick_plot\n",
    "\n",
    "\n",
    "def plot_spec_label(i, predictions_array, test_data, test_labels):\n",
    "  true_label, ms_peaks = test_labels[i], test_data.iloc[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  \n",
    "  spectrum = oms.MSSpectrum()\n",
    "  spectrum.set_peaks((ms_peaks.columns, ms_peaks.values))\n",
    "  plt.show(quick_plot(spectrum, plottype=\"scatter\"))\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(test_labels[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                test_labels[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, test_labels):\n",
    "  true_label = test_labels[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(min(num_images, len(test_labels))):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_spec_label(i, predictions[i], test_data, test_labels)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
